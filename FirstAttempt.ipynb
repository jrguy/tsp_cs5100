{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FirstAttempt.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrguy/tsp_cs5100/blob/main/FirstAttempt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reason for approach as detailed below is due to the curse of dimensionality that occurs with the Traveling Salesman Problem. When the Traveling Salesman Problem is considered as a state space of a larger set, namely the goal of finding exactly n connections for the traveling salesman, it becomes clear as the goal of finding exactly n edges from the set of edges is larger and will grow faster than the goal of finding a path that is a subset of the larger set. For a well connected unique graph, this is necessarily the Binomial Coefficient of N(N-1)/2 Choose N. However, the number of paths that are possible for a given set of nodes is necessarily N!, as that is the permutation of the order of the nodes that preserves the completeness of the set, more readily seen as N(N-1)! for the idea of having boundary edges. \n",
        "\n",
        "This necessitates that the total number of combinations is based on a much larger set, namely the total number of ways for N nodes to as a set choose N edges, with multiple instances of nodes appearing, but each node choosing at least one edge. This comes out to a total of N(N-1)! / Binomial Coefficient (N(N-1)/2, N) \n",
        "\n",
        "When this value is considered for very large N, it can be seen that it drops off to zero at a highly fast rate. This means that the odds of selecting the paths from within the possible combinations of the nodes choosing at least one edge is vanishingly small. \n",
        "\n",
        "Further more, selecting the procedure in such a way as to make the top term as small as possible will limit the number of possible considerations, and as such, aid in finding the best outcomes only in so far as they do not greatly limit the possible chance of their discovery. \n",
        "\n",
        "For this reason, we consider the following implementation progression. \n",
        "First, for a random distribution of nodes, find the most efficient method of selecting an annealing style value of temperature given a number of iterations and nodes, and determining the best outcomes from the set of their values. This is done below, and is based off of a Standford University Mini-Project on the topic, which more can be found on in the link comment in the code. \n",
        "\n",
        "Following along to the above, what  we propose to investigate in a serious manner now is the selection of the outer node of the set and the modulation of the inner series. To do this :    \n",
        "For each node, find the value of the opportunity cost for not selecting the least cost at that node (i.e., If I do not choose my two best links, what cost will I necessarily suffer?)\n",
        "Order the nodes by the opportunity costs in this manner, and as you do, note for each the indices of concern, the costs, and the status as either least cost or second least cost, or third least cost or fourth least cost. \n",
        "Then, from the set of nodes, search for instances where the indices of a least cost for a given node are matched by the transpose of the indices for the least cost of another node. Pay particular attention for instances where a node has a least cost edge or second least cost edge to a node and its transpose has similar or better matching. These instances are to be highly preferred, and will form a secondary set for consideration and investigation. Similarly during this phase, calculate the minim heuristic for the set, where we will determine the valuation of the total edge distances if each node had selected it's least cost edges, not counting those that are highly preferred more than once (no double counting). This is the minimum cost for the set to have each node select at most two edges, and may not form a path. If it does form a path, we have necessarily found the minimum path by the way! Otherwise, from this organization, remove those links that are contested, potentially breaking chains and you will find only those that are highly preferred! This shows that the highly preferred are indeed a promising place to start for the secondary analysis. \n",
        "\n",
        "What we will do then is the following :    \n",
        "0) Perform monte carlo on the entire set to ascertain the minimum path.\n",
        "\n",
        "1) Given a set of nodes ordered by opportunity cost, set these nodes as the outer nodes of the set with their matching edges interior. These are not to be disturbed. Then, perturb the inner set, performing monte carlo style process with connections to attempt to discover the best connection. \n",
        "\n",
        "2) Given a set of highly preferred connections, perturb only those connections that are not part of these sets in the following manner \n",
        "\n",
        "  2a) First, with at least 2 sets if two such sets exist\n",
        "\n",
        "  2b) If more than 2 such sets exist, alter their orientation within the sets\n",
        "  until all combinatios of sets of 2 have been exhausted for analysis. \n",
        "\n",
        "  2c) Proceed to the next higher amount of sets. \n",
        "\n",
        "  2d) Check to see if any such sets can be combined into larger sets. If larger \n",
        "  chained connections are possible, for each such larger chain set, set them \n",
        "  and then perturb the inner portion of these as well.\n",
        "\n",
        "Likely Outcomes : Little to no improvement, as the original modification likely samples from these sets as well. However, may be able to speed up and reduce number of iterations to get a good enough value in the meantime.   \n",
        "\n",
        "Additionally, if you look at the original work we did on the idea of node modality, it can be seen that with this preprocessing approach as noted above, the nature of the nodes in a sparse graph can also be determined ahead of processing. This then gives three main advantages to this pre-process of the TSP :    \n",
        "1) Figure out potential cost based on the number of exceedingly preferred sets within the TSP. The greater the number the greater the cost of this approach, but the more likely a good outcome can be achieved. \n",
        "2) Figure out the potential starting point for best annealing approaches, leading to better outcomes for the set. \n",
        "3) Figure out if the TSP is solvable for the stated graph based on the nature of the nodes in the graph, in time n^2, which is necessarily less than the TSP approaches. This is also incidental in the pre-process, given an additional benefit to completing this before starting the process of monte carlo simulations. \n",
        "\n",
        "In terms of revised schedule :    \n",
        "In the next week complete step 1 as stated above \n",
        "In the week following complete step 2b and integrate with data being pulled in. This is the goal of completion for checkpoint 2. \n",
        "The final project completion will entail finishing 2c and 2d, as well as potentially including a checker for the sparse TSP graphs. "
      ],
      "metadata": {
        "id": "YpXBs_VXV6a2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Given a listOfFourBest by the aforementioned approach, in time n^2, we now \n",
        "# determine the absolute lower bound for the set by the use of nodal connection\n",
        "\n",
        "# The aboslute lower bound must be such that for each node, if it were to select\n",
        "# it's absolute lower bound connections, and if it were to do so allowing for \n",
        "# overlaps, then it is absolutely of the least cost possible. If two nodes over\n",
        "# lap in such a choice it is a promising thing, but if three such overlap in \n",
        "# the form of A-B-C then it is an exceedingly promising thing. \n",
        "\n",
        "# However, if the overlap forms a clique set, A-B-C-A, where A has both B and C \n",
        "# as it's closest and C has both B and A as it's closest, then we have a \n",
        "# less-than-promising triangle. This means that either A or C will need to \n",
        "# settle for an increased cost to the network in the final solution, \n",
        "# and as such, the node of A or C with the least opportunity cost to select \n",
        "# otherwise should be chosen. This could then be propogated outward; \n",
        "# however as already described above, that would lead toward the even less \n",
        "# desirable binomial coefficient of the number of edges where we need to choose \n",
        "# n components. \n",
        "\n",
        "# For now, know that such sets should form less than exceedingly \n",
        "# promising alternate formations, with A-B-C and A and C both selecting their \n",
        "# alternates. These are less in potential value than those chains of 3 where \n",
        "# the ends do not agree, but more value than singular nodes agreeing on their \n",
        "# connections. Regardless, from this original formation, so long as double \n",
        "# counts are not allowed (A-B should be added, but B-A should not), \n",
        "# then we have arrived at an absolute lower bound for the TSP, \n",
        "# as this is the point at which all nodes have exactly two connections. \n",
        "# We have also thus set the bottom level heuristic whereby we can now \n",
        "# incremently improve the heuristic if needed through search for alternate \n",
        "# selections that void the cliques with some minimal opportunity cost.\n",
        "\n",
        "# Now we can turn to the consideration of the advantages of \n",
        "# this pre-process additionally. \n",
        "\n",
        "# 1) Nodes that have two best options but are in \n",
        "# conflict with other nodes can be ranked at those conflict sites by the ones \n",
        "# that will suffer the least immediate opportunity cost (what will X pay in \n",
        "# in order to not have Y?), giving us a priority for investigating their \n",
        "# potential resolutions. \n",
        "\n",
        "# 2) Additionally, we have a way of analyzing if a graph that is sparse is \n",
        "# solvable from an initial consideration. For a sparse graph in this \n",
        "# implementation with undirected edges, any instance of a locked node meeting \n",
        "# with a multi-node where at least two other locked nodes meet necessitates \n",
        "# an impossibility for completing the graph. Any singular node connected to a \n",
        "# multi-node is likewise classically impossible. Further, combinations of \n",
        "# multi-nodes that are in linked formations of cliques greatly lowers likelihood\n",
        "# and greatly increases costs. This can then be used to separate the impossible, \n",
        "# probable but costly, and probable and affordable. \n",
        "\n",
        "# 3) We have a heuristic approach that allows for the bounding of the best \n",
        "# with the added addition that in the case of perfect selections gives the \n",
        "# answer definitively in at best n^2 time, a massive improvement but one not\n",
        "# often to be reached. It also delivers the heuristic original form in an \n",
        "# amount of time less than current best of n^3. This gives a way forward to \n",
        "# improve the heuristic of the approach incrementally. \n",
        "\n",
        "# 4) We also now have a look at some of the higher dimensionality of the \n",
        "# set of promising states. For a set of N nodes, if there are a set of M \n",
        "# exceedingly promising set ups, then for each of the set ups, we need to \n",
        "# consider the situation in which the Mth node is on the outside and none others\n",
        "# are internal, the set up of M on the outside with one of them internal, etc, \n",
        "# for each such exceedingly promising candidate. This allows for selection of \n",
        "# the progression style as well at a pre-process stage. It may be essential that\n",
        "# as many of the exceedingly promising connections be preserved, and if this is\n",
        "# the case the limits the internal variation; conversely, it may be that only \n",
        "# 1 exceedingly promising candidate is desired, and so then the cycle of those \n",
        "# would need to be considered, but none of the internal sections. Based on the \n",
        "# idea that the preservation of all exceedingly promsing candidates can also \n",
        "# reveal the number of conflicts, what is proposed is that, after the \n",
        "# pre-process, a secondary pre-process checks, for how many exceedingly \n",
        "# promising candidates is the number of conflict sites and the number of \n",
        "# conflicts at each site minimized. This is similar to a coverage question, \n",
        "# showing that we have moved to NP-Complete. This is an improvement, but not \n",
        "# much of one. For the current work, we will consider only the potential cost \n",
        "# that would be inherent in running the simulation for rotations of the most\n",
        "# promising candidates in order of the outside nodes with the least conflicts at\n",
        "# terminating points. \n",
        "\n",
        "# 5) We can also now discuss the extension to this work, which is the longest\n",
        "# chain consideration. If in the formation of exceedingly promising sets, it \n",
        "# can be shown that there exist longer chains than that of 3 nodes, such as a \n",
        "# 5 or 7, or longer chain, then the longest chain is that which has the most\n",
        "# promise. If there is a tie in length, again split on end node contestation. \n",
        "# An important thing to avoid here is the formation of cliques however! The \n",
        "# longer a grouped set is, the greater the likelihood of forming a clique. This\n",
        "# necessitates the use of consideration, where, if an additional end node is \n",
        "# merely promising (it has a connection that shares the sentiment of this being\n",
        "# one of the best connections), it needs to be seen that that connection does\n",
        "# not form a cycle within the current chain set. If it would, it may be set at\n",
        "# that length on that side, as any additional selection will incur a necessary\n",
        "# cost of opportunity. However, this needs to be done on both sides of the \n",
        "# chain sets. Once complete, a longest chain can be determined. This should then\n",
        "# set the stage for the consideration, where the permutations now have two forms\n",
        "# The outer chain, our best markov distance, should not be perturbed, but can be\n",
        "# slid from one end to another. Consider A-B-C-D-E-F-G... as if it extended for\n",
        "# some truly long connection. A can be seen to be progenitor in this case. The\n",
        "# key thing though is the node in the middle. The middle node is necessarily the\n",
        "# point from which it must connect to all others. Based on our progressionary \n",
        "# model, we will always have length segments of odd counts, giving a definite\n",
        "# center point. From this, we now have the adjustment possible as below, if \n",
        "# we assume that node I is the center most point \n",
        "# - A - B - C - D - E - F - G - H - I - J - K - L - M - N - O - P - Q -\n",
        "# Where Q and A are the termination points of the chain as currently considered. \n",
        "# We now can consider those situations in which we have \n",
        "# I -> Q at the front of the list and A -> H at the back of the list\n",
        "# This then shortens the total amount of permutations needed for the set as \n",
        "# being of the form N-chainLength"
      ],
      "metadata": {
        "id": "7XaffOf7tpcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on description from Sanford Assignment Here\n",
        "'''\n",
        "  https://www.web.stanford.edu/class/cs168/p7.pdf\n",
        "\n",
        "'''\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "\n",
        "N = 16 # the number of cities\n",
        "\n",
        "# simulate an adjacency matrix of distances \n",
        "distance = np.random.rand(N, N)\n",
        "distance = (distance + distance.T) / 2.0\n",
        "ind_diag = range(N)\n",
        "distance[ind_diag, ind_diag] = 0\n",
        "\n",
        "# Calculate total distance for a given sequence\n",
        "def cal_dist(distance, L):\n",
        "    d = 0\n",
        "    for i in range(len(L)):\n",
        "        d = d + distance[L[i % N], L[(i + 1) % N]]\n",
        "    return d\n",
        "\n",
        "def findMinimFour(AdjacencyList): \n",
        "  '''\n",
        "    findMinimFour returns a list of lists that for each for of the adj. list\n",
        "    contains a list of the four minimum connections in order for a given row, \n",
        "    including the indices involved, then the cost, then the rank for the item. \n",
        "    This necessarily entails looping over the entire set twice in the brute\n",
        "    force method. Better methodologies for determining the minimum four of the \n",
        "    unsorted set would be needed in such a way that the original values are not\n",
        "    perturbed. At end returns the set of such combinations for the adj. list \n",
        "  '''\n",
        "  listOfFourBestByRow = []\n",
        "  for i in range(len(AdjacencyList)):\n",
        "    currentRow = [] \n",
        "    leastMin = math.inf\n",
        "    secondLeastMin = math.inf\n",
        "    thirdLeastMin = math.inf\n",
        "    fourthLeastMin = math.inf\n",
        "    indexSetLeast = []\n",
        "    indexSetSecondLeast = []\n",
        "    indexSetThirdLeast = [] \n",
        "    indexSetFourthLeast = [] \n",
        "    for j in range(len(AdjacencyList[i])):\n",
        "      if i == j:\n",
        "        continue # No need to do the zero entries \n",
        "      else: \n",
        "        if AdjacencyList[i][j] < leastMin and len(indexSetLeast)==0:\n",
        "          indexSetLeast = [i, j]\n",
        "          leastMin = AdjacencyList[i][j]\n",
        "        elif AdjacencyList[i][j] < leastMin and len(indexSetLeast) == 2: \n",
        "          if len(indexSetSecondLeast) == 0: \n",
        "            indexSetSecondLeast = [indexSetLeast[0], indexSetLeast[1]]\n",
        "            secondLeastMin = leastMin\n",
        "            leastMin = AdjacencyList[i][j]\n",
        "            indexSetLeast = [i, j]\n",
        "          elif len(indexSetSecondLeast) == 2: \n",
        "            if len(indexSetThirdLeast) == 0: \n",
        "              indexSetThirdLeast = [indexSetSecondLeast[0], indexSetSecondLeast[1]]\n",
        "              thirdLeastMin = secondLeastMin\n",
        "              indexSetSecondLeast = [indexSetLeast[0], indexSetLeast[1]]\n",
        "              secondLeastMin = leastMin\n",
        "              leastMin = AdjacencyList[i][j]\n",
        "              indexSetLeast = [i, j]\n",
        "            elif len(indexSetThirdLeast) == 2:  \n",
        "                indexSetFourthLeast = [indexSetThirdLeast[0], indexSetThirdLeast[1]]\n",
        "                fourthLeastMin = thirdLeastMin\n",
        "                indexSetThirdLeast = [indexSetSecondLeast[0], indexSetSecondLeast[1]]\n",
        "                thirdLeastMin = secondLeastMin\n",
        "                indexSetSecondLeast = [indexSetLeast[0], indexSetLeast[1]]\n",
        "                secondLeastMin = leastMin\n",
        "                leastMin = AdjacencyList[i][j]\n",
        "                indexSetLeast = [i, j]\n",
        "        elif AdjacencyList[i][j] < secondLeastMin and len(indexSetSecondLeast) == 0:\n",
        "            indexSetSecondLeast = [i, j]\n",
        "            secondLeastMin = AdjacencyList[i][j]\n",
        "        elif AdjacencyList[i][j] < secondLeastMin and len(indexSetSecondLeast) == 2:\n",
        "          if len(indexSetThirdLeast) == 0: \n",
        "              indexSetThirdLeast = [indexSetSecondLeast[0], indexSetSecondLeast[1]]\n",
        "              thirdLeastMin = secondLeastMin\n",
        "              indexSetSecondLeast = [i, j]\n",
        "              secondLeastMin = AdjacencyList[i][j]\n",
        "          elif len(indexSetThirdLeast) == 2: \n",
        "              indexSetFourthLeast = [indexSetThirdLeast[0], indexSetThirdLeast[1]]\n",
        "              fourthLeastMin = thirdLeastMin\n",
        "              indexSetThirdLeast = [indexSetSecondLeast[0], indexSetSecondLeast[1]]\n",
        "              thirdLeastMin = secondLeastMin\n",
        "              indexSetSecondLeast = [i, j]\n",
        "              secondLeastMin = AdjacencyList[i][j]\n",
        "        elif AdjacencyList[i][j] < thirdLeastMin and len(indexSetThirdLeast) == 0: \n",
        "          indexSetThidLeast = [i, j]\n",
        "          thirdLeastMin = AdjacencyList[i][j]\n",
        "        elif AdjacencyList[i][j] < thirdLeastMin and len(indexSetThirdLeast) == 2: \n",
        "          indexSetFourthLeast = [indexSetThirdLeast[0], indexSetThirdLeast[1]]\n",
        "          fourthLeastMin = thirdLeastMin\n",
        "          thirdLeastMin = AdjacencyList[i][j]\n",
        "          indexSetThirdLeast = [i, j]\n",
        "        elif AdjacencyList[i][j] < fourthLeastMin :\n",
        "          indexSetFourthLeast = [i, j]\n",
        "          fourthLeastMin = AdjacencyList[i][j] \n",
        "        else:\n",
        "          continue\n",
        "        # End chained set \n",
        "      # End outer chain component loop goes to next j value here \n",
        "    # Exit J For Loop, no return here, but update larger set\n",
        "    currentRowOpportunityCost = (fourthLeastMin + thirdLeastMin) - (secondLeastMin + leastMin)\n",
        "    currentRow = [leastMin, indexSetLeast[0], indexSetLeast[1], \n",
        "                  secondLeastMin, indexSetSecondLeast[0], indexSetSecondLeast[1], \n",
        "                  thirdLeastMin, indexSetThirdLeast[0], indexSetThirdLeast[1], \n",
        "                  fourthLeastMin, indexSetFourthLeast[0], indexSetFourthLeast[1], \"currentRow Opportunity Cost: \", currentRowOpportunityCost]\n",
        "    listOfFourBestByRow.append(currentRow)\n",
        "  # Exit I for Loop, return should be at this indent \n",
        "  return listOfFourBestByRow\n",
        "# The exit point \n",
        "\n",
        "bestFourByRowOfAdjacencyMatrix = findMinimFour(distance)\n",
        "print(\"Current Adjacency Matrix Below \")\n",
        "for row in range(len(distance)):\n",
        "  print(distance[row])\n",
        "print(\"\\n\")\n",
        "print(\"Best 4 neighbors in adjacency matrix below \")\n",
        "for row in bestFourByRowOfAdjacencyMatrix:\n",
        "  print(row)\n",
        "print(\"\\n\")\n",
        "\n",
        "def simulateSet(numberOfSimulations:int=10, TVal:int = -1):\n",
        "  setOfBestDistances = []\n",
        "  setOfBestPaths = []\n",
        "  for j in range(numberOfSimulations):\n",
        "    if TVal == -1:\n",
        "      T = 1000\n",
        "    else:\n",
        "      T = TVal\n",
        "    ITER = 100000\n",
        "    L = np.arange(N)\n",
        "    print(\"Original L  and distance: \", L)\n",
        "    best = L\n",
        "    bestDistance = cal_dist(distance, L)\n",
        "    print (cal_dist(distance, L)) # initial distance\n",
        "    dist_all = []\n",
        "    for i in range(ITER):\n",
        "        a = np.random.randint(1, N - 1) # Pick a random value in range for your set\n",
        "        d_t = cal_dist(distance, L) # Get the distance you currently have \n",
        "        dist_all.append(d_t) # Put this in the list that will track distance over time\n",
        "        L_tmp = copy.copy(L) # Make a copy \n",
        "        L_tmp[[a, (a + 1)%N]] = L_tmp[[(a + 1)%N, a]] # Set the L_temp at the position and position+1 modulo N to the value at position+1 module N and position (does the swap of the value positions)\n",
        "        L_tmp_dist = cal_dist(distance, L_tmp) # Get the distance of the new temporary form (don't know if you'll keep it yet or not)\n",
        "        delta_d = cal_dist(distance, L_tmp) - d_t # Get the distance of the new set up \n",
        "        if delta_d < 0 or ( T > 0 and random.random() < math.exp(-1*delta_d/T)): # Make a decision based on either improvement, or based on random selection\n",
        "          L = L_tmp\n",
        "        if d_t < bestDistance:\n",
        "          best = L_tmp\n",
        "          bestDistance = cal_dist(distance, L_tmp)\n",
        "        if T > 3: \n",
        "          T -= 2\n",
        "        else: \n",
        "            T = float(T) / (float(i)+(1.0*(TVal+1)))\n",
        "    print(\"Final L and distance : \", L)\n",
        "    finalDistance = cal_dist(distance, L)\n",
        "    print (finalDistance) # final distance\n",
        "    plt.plot(dist_all)\n",
        "    setOfBestDistances.append(finalDistance)\n",
        "    setOfBestPaths.append(L)\n",
        "  minDist = min(setOfBestDistances)\n",
        "  bestPath = setOfBestPaths[setOfBestDistances.index(minDist)]\n",
        "  print(\"After \", numberOfSimulations, \" the best path and distance found below\")\n",
        "  print(minDist)\n",
        "  print(bestPath)\n",
        "\n",
        "def simulateBiggerGroupsOfSets(numberOfSimulations:int = 10):\n",
        "  # Couple rounds of tests later and there seems to be a discrepancy towards \n",
        "  # different temperatures. Varying temperature may be more effective in the long run. \n",
        "  # Seems to be somewhere above 10 and below 10000, which is a range to be sure. \n",
        "  # Also may be that different temperatures work better for different set ups as well. \n",
        "  # TList = [0, 1, 10, 100, 1000, 10000, 50000, 100000]\n",
        "  TList = [10, 100, 1000]\n",
        "  for k in range(len(TList)):\n",
        "    print(\"Results for T = \", TList[k])\n",
        "    simulateSet(10, TList[k])\n",
        "    print(\"End Results for set \\n\\n\")\n",
        "\n",
        "simulateBiggerGroupsOfSets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zgtHqyqsmPPq",
        "outputId": "cd2f3c5f-684a-467b-fa73-b10d619ec512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Adjacency Matrix Below \n",
            "[0.         0.63636779 0.95267656 0.48693197 0.94284956 0.78751455\n",
            " 0.41297084 0.52126369 0.53606532 0.48664191 0.61942467 0.36668916\n",
            " 0.8100567  0.27225714 0.5008984  0.16605895]\n",
            "[0.63636779 0.         0.60514473 0.22392665 0.2695907  0.69784448\n",
            " 0.62252248 0.66457461 0.44436289 0.55974547 0.03436502 0.40279076\n",
            " 0.17948437 0.40175321 0.60772469 0.50134441]\n",
            "[0.95267656 0.60514473 0.         0.62330711 0.62499572 0.47441359\n",
            " 0.19649663 0.27370085 0.54714272 0.36303453 0.16456014 0.30335926\n",
            " 0.46753009 0.6353012  0.47538299 0.46413227]\n",
            "[0.48693197 0.22392665 0.62330711 0.         0.40215174 0.68369993\n",
            " 0.73516585 0.40823111 0.71151107 0.4045052  0.60891261 0.45952569\n",
            " 0.52489252 0.51806245 0.73611358 0.46807069]\n",
            "[0.94284956 0.2695907  0.62499572 0.40215174 0.         0.45169717\n",
            " 0.9289113  0.73985245 0.11731992 0.54169504 0.50142858 0.54800929\n",
            " 0.7932254  0.5911885  0.72198212 0.51706662]\n",
            "[0.78751455 0.69784448 0.47441359 0.68369993 0.45169717 0.\n",
            " 0.28156918 0.72318295 0.61220387 0.44066414 0.40489811 0.3469775\n",
            " 0.13699847 0.82573094 0.48074242 0.40460709]\n",
            "[0.41297084 0.62252248 0.19649663 0.73516585 0.9289113  0.28156918\n",
            " 0.         0.14714953 0.19175889 0.60787749 0.539321   0.60938105\n",
            " 0.47407803 0.50182603 0.23039517 0.18226121]\n",
            "[0.52126369 0.66457461 0.27370085 0.40823111 0.73985245 0.72318295\n",
            " 0.14714953 0.         0.44123141 0.28815364 0.8792921  0.87018593\n",
            " 0.26544212 0.4763101  0.49636434 0.53800005]\n",
            "[0.53606532 0.44436289 0.54714272 0.71151107 0.11731992 0.61220387\n",
            " 0.19175889 0.44123141 0.         0.4000223  0.04497934 0.70130517\n",
            " 0.20372562 0.32532064 0.71426723 0.59278075]\n",
            "[0.48664191 0.55974547 0.36303453 0.4045052  0.54169504 0.44066414\n",
            " 0.60787749 0.28815364 0.4000223  0.         0.87515041 0.37061431\n",
            " 0.60760392 0.50277712 0.69216924 0.38906828]\n",
            "[0.61942467 0.03436502 0.16456014 0.60891261 0.50142858 0.40489811\n",
            " 0.539321   0.8792921  0.04497934 0.87515041 0.         0.67037106\n",
            " 0.2778658  0.21731594 0.54119524 0.20979339]\n",
            "[0.36668916 0.40279076 0.30335926 0.45952569 0.54800929 0.3469775\n",
            " 0.60938105 0.87018593 0.70130517 0.37061431 0.67037106 0.\n",
            " 0.33902464 0.6014312  0.30905092 0.1913875 ]\n",
            "[0.8100567  0.17948437 0.46753009 0.52489252 0.7932254  0.13699847\n",
            " 0.47407803 0.26544212 0.20372562 0.60760392 0.2778658  0.33902464\n",
            " 0.         0.11591107 0.44843532 0.74884376]\n",
            "[0.27225714 0.40175321 0.6353012  0.51806245 0.5911885  0.82573094\n",
            " 0.50182603 0.4763101  0.32532064 0.50277712 0.21731594 0.6014312\n",
            " 0.11591107 0.         0.51877425 0.49574706]\n",
            "[0.5008984  0.60772469 0.47538299 0.73611358 0.72198212 0.48074242\n",
            " 0.23039517 0.49636434 0.71426723 0.69216924 0.54119524 0.30905092\n",
            " 0.44843532 0.51877425 0.         0.29458225]\n",
            "[0.16605895 0.50134441 0.46413227 0.46807069 0.51706662 0.40460709\n",
            " 0.18226121 0.53800005 0.59278075 0.38906828 0.20979339 0.1913875\n",
            " 0.74884376 0.49574706 0.29458225 0.        ]\n",
            "\n",
            "\n",
            "Best 4 neighbors in adjacency matrix below \n",
            "[0.16605895288390082, 0, 15, 0.2722571404932358, 0, 13, 0.36668916444533667, 0, 11, 0.4129708374631818, 0, 6, 'currentRow Opportunity Cost: ', 0.34134390853138186]\n",
            "[0.03436502209783571, 1, 10, 0.17948437340860873, 1, 12, 0.223926653819002, 1, 3, 0.26959070122917766, 1, 4, 'currentRow Opportunity Cost: ', 0.27966795954173523]\n",
            "[0.16456013865377933, 2, 10, 0.1964966304542654, 2, 6, 0.2737008457771656, 2, 7, 0.3033592633355371, 2, 11, 'currentRow Opportunity Cost: ', 0.21600334000465793]\n",
            "[0.223926653819002, 3, 1, 0.4021517362912949, 3, 4, 0.40450520312817745, 3, 9, 0.4082311090489387, 3, 7, 'currentRow Opportunity Cost: ', 0.1866579220668193]\n",
            "[0.1173199204373927, 4, 8, 0.26959070122917766, 4, 1, 0.4021517362912949, 4, 3, 0.45169716565354723, 4, 5, 'currentRow Opportunity Cost: ', 0.4669382802782717]\n",
            "[0.1369984667058574, 5, 12, 0.2815691818901271, 5, 6, 0.34697750274687456, 5, 11, 0.40460709430799185, 5, 15, 'currentRow Opportunity Cost: ', 0.33301694845888197]\n",
            "[0.14714953250661084, 6, 7, 0.18226120961680736, 6, 15, 0.19175889140209285, 6, 8, 0.1964966304542654, 6, 2, 'currentRow Opportunity Cost: ', 0.058844779732940056]\n",
            "[0.14714953250661084, 7, 6, 0.2654421167378507, 7, 12, 0.2737008457771656, 7, 2, 0.28815363513593784, 7, 9, 'currentRow Opportunity Cost: ', 0.1492628316686419]\n",
            "[0.04497934338989845, 8, 10, 0.1173199204373927, 8, 4, 0.19175889140209285, 8, 6, 0.20372561556708263, 8, 12, 'currentRow Opportunity Cost: ', 0.23318524314188432]\n",
            "[0.28815363513593784, 9, 7, 0.36303453056110047, 9, 2, 0.3706143108667144, 9, 11, 0.3890682779177801, 9, 15, 'currentRow Opportunity Cost: ', 0.10849442308745616]\n",
            "[0.03436502209783571, 10, 1, 0.04497934338989845, 10, 8, 0.16456013865377933, 10, 2, 0.20979339401611663, 10, 15, 'currentRow Opportunity Cost: ', 0.2950091671821618]\n",
            "[0.19138749559804186, 11, 15, 0.3033592633355371, 11, 2, 0.30905091890313463, 11, 14, 0.33902464159089774, 11, 12, 'currentRow Opportunity Cost: ', 0.15332880156045342]\n",
            "[0.11591107124826988, 12, 13, 0.1369984667058574, 12, 5, 0.17948437340860873, 12, 1, 0.20372561556708263, 12, 8, 'currentRow Opportunity Cost: ', 0.13030045102156407]\n",
            "[0.11591107124826988, 13, 12, 0.21731594296776446, 13, 10, 0.2722571404932358, 13, 0, 0.3253206357916459, 13, 8, 'currentRow Opportunity Cost: ', 0.2643507620688474]\n",
            "[0.23039516982637448, 14, 6, 0.29458224533353916, 14, 15, 0.30905091890313463, 14, 11, 0.44843532057941976, 14, 12, 'currentRow Opportunity Cost: ', 0.23250882432264075]\n",
            "[0.16605895288390082, 15, 0, 0.18226120961680736, 15, 6, 0.19138749559804186, 15, 11, 0.20979339401611663, 15, 10, 'currentRow Opportunity Cost: ', 0.0528607271134503]\n",
            "\n",
            "\n",
            "Results for T =  10\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  3  1  2  5  4  9  7  6  8 10 11 12 13 14 15]\n",
            "5.5605727734707235\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  3  1  4  5  2  6  8  7  9 11 12 10 15 14 13]\n",
            "5.307112433225231\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  3  1  4  5  6  2  7  9  8 10 11 12 13 14 15]\n",
            "5.02179065196099\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  3  1  4  5  2  6  8  9  7 12 10 15 11 14 13]\n",
            "5.027562658440332\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  2  4  1  3  5  6  8  7  9 11 14 12 13 10 15]\n",
            "5.7947825972311895\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  1  2  5  4  3  7  6  8  9 11 12 13 10 14 15]\n",
            "5.761639258909927\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  3  1  4  5  2  6  8  7  9 11 12 13 10 14 15]\n",
            "5.068903059039898\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  3  1  4  5  2  7  6  8 10 13  9 11 12 14 15]\n",
            "4.902957234440561\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  2  1  3  5  4  8  6  7  9 11 12 13 10 14 15]\n",
            "5.706229429968091\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  3  1  4  5  2  7  6 10  8  9 11 12 13 14 15]\n",
            "5.1166985848420365\n",
            "After  10  the best path and distance found below\n",
            "4.902957234440561\n",
            "[ 0  3  1  4  5  2  7  6  8 10 13  9 11 12 14 15]\n",
            "End Results for set \n",
            "\n",
            "\n",
            "Results for T =  100\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  3  1  4  2  7  9  5 10  8 12 13 14 11 15  6]\n",
            "4.991922521305168\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  3  4  1 10  2  6  7 12  5 11  9  8 13 14 15]\n",
            "4.526036517762795\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  2  4  1  3  5  9  7  6  8 10 14 13 12 11 15]\n",
            "5.739946760893384\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  7  2  4  1  3  9  6  5 12  8 11 15 10 13 14]\n",
            "5.887628219176622\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  6  2  4  1  3  7  5 11  9  8 10 15 14 12 13]\n",
            "5.36296723173759\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  3  5  6  7  2  1  4  8  9 11 14 15 10 12 13]\n",
            "5.115204003105839\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  1  4  3  9  5  2 10  8 13  7  6 15 11 12 14]\n",
            "5.448019991443658\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  3  1  4  5  6  2 11 15 10  8 13  9  7 12 14]\n",
            "4.990759035423615\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  2  5  4  1  3  7  6  9 11 15 10  8 12 13 14]\n",
            "5.691646685242705\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  5  1  3  7  6  2  9  4  8 10 12 11 15 14 13]\n",
            "5.422083353657997\n",
            "After  10  the best path and distance found below\n",
            "4.526036517762795\n",
            "[ 0  3  4  1 10  2  6  7 12  5 11  9  8 13 14 15]\n",
            "End Results for set \n",
            "\n",
            "\n",
            "Results for T =  1000\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  7  2  6 14  5  3  8 12 11 15  9 13 10  1  4]\n",
            "6.187914137103495\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  9  1 10  2  5 12 11 15  7  8  4  3 13 14  6]\n",
            "5.566042563976773\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  5  8 10  1 12 11  6  7 13  3  4 15 14  2  9]\n",
            "6.287334972302137\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  4  8 12  7  6 14  5  9 13  1 10  2 11  3 15]\n",
            "5.328758560056457\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  5  2  7  3 15  8  4  1  6 14 12 11  9 13 10]\n",
            "6.742131812942688\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  9  2  7 12 14  4  8  6 15  3  5 10  1 11 13]\n",
            "5.918089737132708\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  9  4  2 11  1 12 14  6 15 10  8  5  3  7 13]\n",
            "6.107533667271057\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0 12 10  2  7  4  5 11  9  8  1  3 15  6 14 13]\n",
            "6.175395219648089\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  4  7 12 13 15  6  2  5  8  9  3  1 10 14 11]\n",
            "6.304932063567019\n",
            "Original L  and distance:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "6.968513597730046\n",
            "Final L and distance :  [ 0  8  7  6 14 15  5  4  3 11 12 13  2 10  1  9]\n",
            "5.702954821869087\n",
            "After  10  the best path and distance found below\n",
            "5.328758560056457\n",
            "[ 0  4  8 12  7  6 14  5  9 13  1 10  2 11  3 15]\n",
            "End Results for set \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After considerations and consultation with both Dr. Alan Jamieson and Dr. Lindsay Jamieson, the update process has been modified to now ascertain the following for a promising chain. As such, the program will need to be refocused on the development of a ascertainment of promising lengths before reaching a negative valuation. Those chains that can complete the entirety without a negative valuation are to be desired as they move through the network, and are detailed below. \n",
        "\n",
        "Consider a singular node that wishes to make two connections, for now labeled as A, B, and C. A wishes to connect to B and C. This implies that for this connection to be a valid and useful connection that the chain of B-A-C must have a positive valuation as detailed below \n",
        "\n",
        "Weight of A connection to best two nodes not B or C - weight of A connection to B and C. \n",
        "\n",
        "If this is negative, it means that there were better nodes than these to select, which implies a contradiction. \n",
        "\n",
        "Weight of B not A or C - weight of B-A and not C \n",
        "\n",
        "If this is negative it implies that B has a better connection to two other nodes that are not c or a than it does to have a connection to a and c. This can be negative, and would mean that the weight of B-A and not C is greater than B connected to two others. This would mean that B does not prefer A, and would be a key point to stop on the search for a promising chain. \n",
        "\n",
        "Weight of C not A or B - weight of C-A and not B\n",
        "\n",
        "Similar to the above, this is to ascertain that C desires A as well in mutual reasons. \n",
        "\n",
        "In all of the above cases, we are looking for the minimal cost weight on each consideration. \n",
        "\n",
        "Now we confirm the weight is valid with the next two considerations. \n",
        "\n",
        "Weight of A-B-C - A-B-notC\n",
        "\n",
        "If this is positive we know that the weight of A-B-C is greater than the weight of B-A-notC. This would mean that a clique is avoided and that is a good thing. If this is negative, that would mean we would form a clique, and again this is a good point to stop. \n",
        "\n",
        "Weight of A-C-B - A-C-notB\n",
        "\n",
        "Again for the other side. This shows that we are not going to form a clique. \n",
        "\n",
        "If all of the above a true and pass, we have ascertained the length of size 3 preliminarily. For the purpose of this project, we are only going to consider preliminary considerations for validation. More formal validations will await a later point. \n",
        "\n",
        "If we have not desired to form a clique, and we have mutual desire to form a chain, and we have a chain that is valid for the network, then we are now ready to consider the extension of the chain in a preliminary fashion. \n",
        "\n",
        "For each extension, the above does not change very much. In this case, we are now considering the addition of nodes D and E to B and C respectively. \n",
        "\n",
        "Prior Weight\n",
        "\n",
        "Weight of B notNetwork1 notNetwork2 - D-B-A (Similar to A eval at prior)\n",
        "\n",
        "Weight of C notNetwork1 notNetwork2 - E-C-A (Similar to A eval at prior)\n",
        "\n",
        "Weight of D notNetwork1 notNetwork2 - B-D-NotNetwork1 (mutual desires) \n",
        "\n",
        "Weight of E notNetwork1 notNetwork2 - C-E-NotNetwork1 (mutual desires) \n",
        "\n",
        "(min(Weight of B-D-networkNode)) - B-D-NotNetwork1 (non-clique) \n",
        "\n",
        "(min(Weight of C-E-networkNode)) - C-E-NotNetwork1 (non-clique) \n",
        "\n",
        "Note that as the expansion grows, the prior weight is absorbed. Note also that the validation of the non-clique and mutual desires must occur for any combination in the set. This then shows that this is a satisfying chain, but not a validated chain. To validate would require checking against the converse, which is considered in a later section. \n",
        "\n",
        "For now, note that the satisfying constraints above increase in cost of consideration as the size of the chain grows, but that the costs incurred only ever increase by a value of N. This makes this an approach that is valid much more quickly, especially, as it can be considered that all of the right hand side components can be pre-calculated. This is valuable especially for the last two considerations, which are of clique status. By doing this, as the minimum will be selected, a functionality to report on the minimum weight if greater than the non-clique constraint can be utilized, allowing again for early stopping on larger sets. \n",
        "\n",
        "From this, we can establish chains that are promising up to a certain length in a given amount of time. Now we can turn to the idea of validation. \n",
        "\n",
        "For a confirmation of a chain of length 3 it can be seen that the above needing to sum to a total positive value is a component of the proof of this. To further ascertain this, the next components are required as well. \n",
        "\n",
        "For all other nodes in the graph \n",
        "\n",
        "Do all nodes agree that to connect to one of the network components is more expensive than to not connect to one of the network components? \n",
        "\n",
        "Do all nodes agree that to connect to two of the network components is more expensive than to not connect to one of the network components? \n",
        "\n",
        "In case of disagreements, by how much do they disagree? \n",
        "\n",
        "V notNetwork1 notNetwork2 - V network notNetwork1 \n",
        "\n",
        "If this is positive, this means that they disagree. Record amount of disagree. \n",
        "\n",
        "V notNetwork1 notNetwork2 - V network1 network2 \n",
        "\n",
        "If this is positive, this means that they disagree. Record amount of disagree. \n",
        "\n",
        "If sum of disagreement is greater than promise of chain, this chain is voidable at this length. This means one size less than this is promising. If sum of disagreement is less than promise of chain, the chain is valid up to that point. \n",
        "\n",
        "This can then continue for the size of the combination, but can quickly seen to grow in scale. Some ways to avoid the pitfall is early stop due to size elimination. This would allow the promising chain at largest length to have this run at the minimal component, and then progress upwards from there. \n",
        "\n",
        "That said, this is a distressing finding as well, as it can be seen that the validation process necessarily expands in size at a binomial rate. Consider that for a chain of length 3, the valuation involves compuational steps at 3 choose 1 * n steps, 3 choose 2 * n steps. For a length of 5, that would mean 5 choose 1, 5 choose 2, 5 choose 3, 5 choose 4 all times n steps, where we are now assuming that the n steps is based on the much larger set size versus the chain length. \n",
        "\n",
        "Thus it can be seen that for a highly densly connected graph, as the size of the graph grows there is no way to either find the path through elimination or considerations that validate the graph. Even considering that as the length of the chain must always remain within half the size of the graph, there is no way to circumvent this impact on a complete graph. \n",
        "\n",
        "Either the probability of finding the path is too small \n",
        "\n",
        "(N! / (avg. density (avg. density - 1))^N)\n",
        "\n",
        "Or the cost of validating chains within the graph grows too quickly \n",
        "\n",
        "O(Summation i=1 to M-1 {(N-M) * (M choose i) * shift amounts})\n",
        "\n",
        "Where M is the length of the chain and N-M represents the positive value of the total number of nodes that is not in the chain currently, and shift amounts is the amount of places that the key value can be shifted to, as that location can vary, thus varying the chain cost. \n",
        "\n",
        "This does hint a way forward for sparser graphs though. This shows that for a sparse graph, it may be possible to arrive at a lower cost with higher probability through validation if instead of N only the subset n that are connected to a given component are considered. This can greatly limit the cost, and potentially open up avenues of further research. \n",
        "\n",
        "For now, this theory work yields the following findings: \n",
        "\n",
        "A clear simple way to determine path impossibility through the states of the nodes {nodes of degree greater than 2 connecting to 3 nodes or more of degree 2}\n",
        "\n",
        "A clear probability showcasing that as average density increases, the probability decreases {N! / ((avg density (avg density -1))^N)} of succesfully finding a path through combinatorial methods. \n",
        "\n",
        "A clear cost validation that showcases increases in costs as chains grow in size versus the total size of the set \n",
        "{O(Summation i=1 to M-1 [(N-M)*(M choose i) * shift amounts])}\n",
        "\n",
        "Attempted implementation of the promising chain process with implementation for a monte carlo markov method and analysis of theoretical comparison now follows. \n"
      ],
      "metadata": {
        "id": "OVd04UZxHwD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Given an adjacency matrix, row number -> return tuple of rows in chain if promising or False \n",
        "# For a given row, determine if there exists a promising chain by \n",
        "# First, get cost of chain B-A-C and find difference with NOTB,C - A - NOTB,C2\n",
        "# Then, get cost of NOTA,C - B - NOTA,C and find difference with A-B-NOTA,C\n",
        "# Do same with C : NOTA,B - C - NOTA,B and find difference with A-C-NOTA,B\n",
        "# Record both of these, and sum with initial value. \n",
        "# Then get cost of A-B-C and find difference with A-B-NOTA,C. If negative, can discard -> implies clique forming \n",
        "# Do not sum with initial. \n",
        "# Do same for A-C-B and find difference with A-C-NOTA,B. If negative, can discard -> implies clique forming\n",
        "# Do not sum with initial. \n",
        "# We do not sum non-clique forming as that is to be expected of promising chains.\n",
        "\n",
        "def promising_sequence(adjacencyMatrix, rowNum):\n",
        "  # Get minimum indices and values for the stated rowNumber\n",
        "  # Get minimum indices and values for the paired rows not including each other\n",
        "  # Do analysis\n",
        "  # For now, assume undirected graph for adjacency matrix \n",
        "  minB = math.inf\n",
        "  minC = math.inf\n",
        "  indexB=[rowNum, -1]\n",
        "  indexC=[rowNum, -1]\n",
        "  # Loop through and get the minimum B and C for the set up, as well as their\n",
        "  # matrice locations. Note that you will then use the second value as the\n",
        "  # row value for these going forward. \n",
        "  for j in range(len(adjacencyMatrix[rowNum])):\n",
        "    if j == rowNum:\n",
        "      continue\n",
        "    else:\n",
        "      if minB > adjacencyMatrix[rowNum][j]:\n",
        "        if minB == math.inf:\n",
        "          minB = adjacencyMatrix[rowNum][j]\n",
        "          indexB = [rowNum, j]\n",
        "        else:\n",
        "          minC = minB\n",
        "          indexC = [rowNum, indexB[1]]\n",
        "          minB = adjacencyMatrix[rowNum][j]\n",
        "          indexB = [rowNum, j]\n",
        "  # Now we can go and get the mins for B and for C that are not A, B and A, C \n",
        "  Bmin1=math.inf\n",
        "  Bmin2=math.inf\n",
        "  BIndexList1 = [indexB[1], -1]\n",
        "  BIndexList2 = [indexB[1], -1]\n",
        "  Cmin1=math.inf\n",
        "  Cmin2=math.inf\n",
        "  CIndexList1 = [indexC[1], -1]\n",
        "  CIndexList2 = [indexC[1], -1]\n",
        "  # Do B first \n",
        "  for j in range(len(adjacencyMatrix[indexB[1]])):\n",
        "    if j == indexB[1] or j == rowNum or j == indexC[1]:\n",
        "      continue # Don't match these ones\n",
        "    else:\n",
        "      if Bmin1 > adjacencyMatrix[indexB[1]][j]:\n",
        "        if Bmin1 == math.inf:\n",
        "          Bmin1 = adjacencyMatrix[indexB[1]][j]\n",
        "          BIndexList1[indexB[1], j]\n",
        "        else:\n",
        "          Bmin2 = Bmin1\n",
        "          BIndexList2 = [indexB[1], BIndexList1[1]]\n",
        "          Bmin1 = adjacencyMatrix[indexB[1]][j]\n",
        "          BIndexList1 = [indexB[1], j]\n",
        "\n",
        "  # Similarly now for C \n",
        "  for j in range(len(adjacencyMatrix[indexC[1]])):\n",
        "    if j == indexB[1] or j == rowNum or j == indexC[1]:\n",
        "      continue # Don't match these ones\n",
        "    else:\n",
        "      if Cmin1 > adjacencyMatrix[indexC[1]][j]:\n",
        "        if Cmin1 == math.inf:\n",
        "          Cmin1 = adjacencyMatrix[indexC[1]][j]\n",
        "          CIndexList1[indexC[1], j]\n",
        "        else:\n",
        "          Cmin2 = Cmin1\n",
        "          CIndexList2 = [indexC[1], CIndexList1[1]]\n",
        "          Cmin1 = adjacencyMatrix[indexC[1]][j]\n",
        "          CIndexList1 = [indexC[1], j]\n",
        "\n",
        "  # Once more for A but now without B and C. Condense this later.\n",
        "  AaltMin1 = math.inf\n",
        "  AaltMin2 = math.inf\n",
        "  Aalt1Index = [rowNumber, -1]\n",
        "  Aalt2Index = [rowNumber, -1]\n",
        "  for j in range(len(adjacencyMatrix[rowNumber])):\n",
        "    if j == rowNumber or j == indexB[1] or j == indexC[1]:\n",
        "      continue # Don't match these ones \n",
        "    else:\n",
        "      if AaltMin1 > adjacencyMatrix[rowNumber][j]:\n",
        "        if AaltMin1 == math.inf:\n",
        "          AaltMin1 = adjancencyMatrix[rowNumber][j]\n",
        "          Aalt1Index[1] = j\n",
        "        else:\n",
        "          AaltMin2 = AaltMin1\n",
        "          Aalt2Index[rowNumber, Aalt1Index[1]]\n",
        "          AaltMin1 = adjacencyMatrix[rowNumber][j]\n",
        "          Aalt1Index[rowNumber, j]\n",
        "\n",
        "  # 1) Weight of A with not b or c 1 and not b or c 2 \n",
        "  # 2) Weight of A with b and c \n",
        "  # 3) Weight of B with not A or C \n",
        "  # 4) Weight of C with not A or B \n",
        "  # 5) Weight of B with A and not C \n",
        "  # 6) Weight of C with A and not B \n",
        "  # 1 - 2 -> Cost of A not getting B or C (costTotal1)\n",
        "  # 3 - 5 -> Cost of B not getting A (costTotal2)\n",
        "  # 4 - 6 -> Cost of C not getting A (costTotal3)\n",
        "  # 2 - 5 -> Cost of Clique  -> Ignored if negative or 0 (cliqueCheck1)\n",
        "  # 2 - 6 -> Cost of Clique  -> Ignored if negative or 0 (cliqueCheck2)\n",
        "  weightAwithoutBC = AaltMin1+AaltMin2\n",
        "  weightAwithBC = minB + minC\n",
        "  costTotal1 = weightAwithoutBC - weightAwithBC \n",
        "  weightOfBwithoutAC = Bmin1 + Bmin2 \n",
        "  weightOfCwithoutAB = Cmin1 + Cmin2\n",
        "  weightOfBwithAnotC = minB + Bmin1\n",
        "  weightOfCwithAnotB = minC + Cmin1\n",
        "  costTotal2 = weightOfBwithoutAC - weightOfBwithAnotC\n",
        "  costTotal3 = weightOfCwithoutAB - weightOfCwithAnotB\n",
        "  costTotal1 += costTotal2 + costTotal3 \n",
        "  cliqueCheck1 = weightAwithBC - weightOfBwithAnotC\n",
        "  cliqueCheck2 = weightAwithBC - weightOfCwithAnotB\n",
        "\n",
        "  if cliqueCheck1 < 0 or cliqueCheck2 < 0 : \n",
        "    # Avoid cliques \n",
        "    return [False, rowNumber, indexB[1], indexC[1]]\n",
        "  else: \n",
        "    if costTotal1 < 0: \n",
        "      # Avoid non promising chains \n",
        "      return [False, rowNumber, indexB[1], indexC[1]]\n",
        "    else: \n",
        "      return [True, rowNumber, indexB[1], indexC[1]] # These form a promising chain\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GPP-t4BmUKfJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}